{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from einops import *\n",
    "\n",
    "from model import MLPModel, MLPConfig, EigModel, SparseEigModel\n",
    "from utils import define_scheduler_lambda\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "scheduler_epochs = [4, 6, 10]\n",
    "config = MLPConfig(d_model = 300, \n",
    "                   n_layer = 2,\n",
    "                    weight_decay = 0.5,\n",
    "                    latent_noise = 0.33, \n",
    "                    input_noise = 0.33,\n",
    "                    normalization = None,\n",
    "                    epochs = sum(scheduler_epochs) + 50, \n",
    "                    scheduler_epochs = scheduler_epochs,\n",
    "                    scheduler_min_lambda = 0.03,\n",
    "                    scheduler_steps_per = 2,\n",
    "                    )\n",
    "model = MLPModel(config).to('mps')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation | Accuracy: 8.07 %, Loss: 2.3026\n",
      "Epoch [1/70], Step [100/600], CE_loss: 2.2732, loss: 2.2732\n",
      "Epoch [1/70], Step [200/600], CE_loss: 1.8459, loss: 1.8459\n",
      "Epoch [1/70], Step [300/600], CE_loss: 1.5117, loss: 1.5117\n",
      "Epoch [1/70], Step [400/600], CE_loss: 1.0672, loss: 1.0672\n",
      "Epoch [1/70], Step [500/600], CE_loss: 1.1130, loss: 1.1130\n",
      "Epoch [1/70], Step [600/600], CE_loss: 1.1464, loss: 1.1464\n",
      "learning rate = 3e-05\n",
      "Evaluation | Accuracy: 85.65 %, Loss: 0.8878\n",
      "Epoch [2/70], Step [100/600], CE_loss: 0.9354, loss: 0.9354\n",
      "Epoch [2/70], Step [200/600], CE_loss: 0.9400, loss: 0.9400\n",
      "Epoch [2/70], Step [300/600], CE_loss: 0.7141, loss: 0.7141\n",
      "Epoch [2/70], Step [400/600], CE_loss: 0.6910, loss: 0.6910\n",
      "Epoch [2/70], Step [500/600], CE_loss: 0.8968, loss: 0.8968\n",
      "Epoch [2/70], Step [600/600], CE_loss: 0.6513, loss: 0.6513\n",
      "learning rate = 0.00017320508075688773\n",
      "Evaluation | Accuracy: 88.63 %, Loss: 0.6307\n",
      "Epoch [3/70], Step [100/600], CE_loss: 0.8679, loss: 0.8679\n",
      "Epoch [3/70], Step [200/600], CE_loss: 0.8425, loss: 0.8425\n",
      "Epoch [3/70], Step [300/600], CE_loss: 0.5720, loss: 0.5720\n",
      "Epoch [3/70], Step [400/600], CE_loss: 0.3845, loss: 0.3845\n",
      "Epoch [3/70], Step [500/600], CE_loss: 0.5384, loss: 0.5384\n",
      "Epoch [3/70], Step [600/600], CE_loss: 0.4345, loss: 0.4345\n",
      "learning rate = 0.00017320508075688773\n",
      "Evaluation | Accuracy: 91.45 %, Loss: 0.4238\n",
      "Epoch [4/70], Step [100/600], CE_loss: 0.7554, loss: 0.7554\n",
      "Epoch [4/70], Step [200/600], CE_loss: 0.5249, loss: 0.5249\n",
      "Epoch [4/70], Step [300/600], CE_loss: 0.5381, loss: 0.5381\n",
      "Epoch [4/70], Step [400/600], CE_loss: 0.5938, loss: 0.5938\n",
      "Epoch [4/70], Step [500/600], CE_loss: 0.3903, loss: 0.3903\n",
      "Epoch [4/70], Step [600/600], CE_loss: 0.6304, loss: 0.6304\n",
      "learning rate = 0.001\n",
      "Evaluation | Accuracy: 92.99 %, Loss: 0.3361\n",
      "Epoch [5/70], Step [100/600], CE_loss: 0.4751, loss: 0.4751\n",
      "Epoch [5/70], Step [200/600], CE_loss: 0.5940, loss: 0.5940\n",
      "Epoch [5/70], Step [300/600], CE_loss: 0.3403, loss: 0.3403\n",
      "Epoch [5/70], Step [400/600], CE_loss: 0.3932, loss: 0.3932\n",
      "Epoch [5/70], Step [500/600], CE_loss: 0.6402, loss: 0.6402\n",
      "Epoch [5/70], Step [600/600], CE_loss: 0.3717, loss: 0.3717\n",
      "learning rate = 0.001\n",
      "Evaluation | Accuracy: 95.04 %, Loss: 0.2166\n",
      "Epoch [6/70], Step [100/600], CE_loss: 0.4359, loss: 0.4359\n",
      "Epoch [6/70], Step [200/600], CE_loss: 0.4776, loss: 0.4776\n",
      "Epoch [6/70], Step [300/600], CE_loss: 0.4015, loss: 0.4015\n",
      "Epoch [6/70], Step [400/600], CE_loss: 0.7182, loss: 0.7182\n",
      "Epoch [6/70], Step [500/600], CE_loss: 0.3274, loss: 0.3274\n",
      "Epoch [6/70], Step [600/600], CE_loss: 0.2264, loss: 0.2264\n",
      "learning rate = 0.001\n",
      "Evaluation | Accuracy: 95.42 %, Loss: 0.2053\n",
      "Epoch [7/70], Step [100/600], CE_loss: 0.4831, loss: 0.4831\n",
      "Epoch [7/70], Step [200/600], CE_loss: 0.2505, loss: 0.2505\n",
      "Epoch [7/70], Step [300/600], CE_loss: 0.1874, loss: 0.1874\n",
      "Epoch [7/70], Step [400/600], CE_loss: 0.1491, loss: 0.1491\n",
      "Epoch [7/70], Step [500/600], CE_loss: 0.4255, loss: 0.4255\n",
      "Epoch [7/70], Step [600/600], CE_loss: 0.1745, loss: 0.1745\n",
      "learning rate = 0.001\n",
      "Evaluation | Accuracy: 95.47 %, Loss: 0.1942\n",
      "Epoch [8/70], Step [100/600], CE_loss: 0.1367, loss: 0.1367\n",
      "Epoch [8/70], Step [200/600], CE_loss: 0.2372, loss: 0.2372\n",
      "Epoch [8/70], Step [300/600], CE_loss: 0.2929, loss: 0.2929\n",
      "Epoch [8/70], Step [400/600], CE_loss: 0.7714, loss: 0.7714\n",
      "Epoch [8/70], Step [500/600], CE_loss: 0.4089, loss: 0.4089\n",
      "Epoch [8/70], Step [600/600], CE_loss: 0.2714, loss: 0.2714\n",
      "learning rate = 0.001\n",
      "Evaluation | Accuracy: 95.99 %, Loss: 0.1742\n",
      "Epoch [9/70], Step [100/600], CE_loss: 0.3413, loss: 0.3413\n",
      "Epoch [9/70], Step [200/600], CE_loss: 0.2839, loss: 0.2839\n",
      "Epoch [9/70], Step [300/600], CE_loss: 0.3407, loss: 0.3407\n",
      "Epoch [9/70], Step [400/600], CE_loss: 0.4301, loss: 0.4301\n",
      "Epoch [9/70], Step [500/600], CE_loss: 0.2181, loss: 0.2181\n",
      "Epoch [9/70], Step [600/600], CE_loss: 0.2372, loss: 0.2372\n",
      "learning rate = 0.001\n",
      "Evaluation | Accuracy: 95.80 %, Loss: 0.1704\n",
      "Epoch [10/70], Step [100/600], CE_loss: 0.4284, loss: 0.4284\n",
      "Epoch [10/70], Step [200/600], CE_loss: 0.2403, loss: 0.2403\n",
      "Epoch [10/70], Step [300/600], CE_loss: 0.2339, loss: 0.2339\n",
      "Epoch [10/70], Step [400/600], CE_loss: 0.3517, loss: 0.3517\n",
      "Epoch [10/70], Step [500/600], CE_loss: 0.2897, loss: 0.2897\n",
      "Epoch [10/70], Step [600/600], CE_loss: 0.1311, loss: 0.1311\n",
      "learning rate = 0.001\n",
      "Evaluation | Accuracy: 96.14 %, Loss: 0.1665\n",
      "Epoch [11/70], Step [100/600], CE_loss: 0.4969, loss: 0.4969\n",
      "Epoch [11/70], Step [200/600], CE_loss: 0.1586, loss: 0.1586\n",
      "Epoch [11/70], Step [300/600], CE_loss: 0.6468, loss: 0.6468\n",
      "Epoch [11/70], Step [400/600], CE_loss: 0.1526, loss: 0.1526\n",
      "Epoch [11/70], Step [500/600], CE_loss: 0.1631, loss: 0.1631\n",
      "Epoch [11/70], Step [600/600], CE_loss: 0.2299, loss: 0.2299\n",
      "learning rate = 0.00036787944117144236\n",
      "Evaluation | Accuracy: 96.20 %, Loss: 0.1812\n",
      "Epoch [12/70], Step [100/600], CE_loss: 0.1683, loss: 0.1683\n",
      "Epoch [12/70], Step [200/600], CE_loss: 0.3816, loss: 0.3816\n",
      "Epoch [12/70], Step [300/600], CE_loss: 0.1183, loss: 0.1183\n",
      "Epoch [12/70], Step [400/600], CE_loss: 0.1310, loss: 0.1310\n",
      "Epoch [12/70], Step [500/600], CE_loss: 0.0404, loss: 0.0404\n",
      "Epoch [12/70], Step [600/600], CE_loss: 0.1823, loss: 0.1823\n",
      "learning rate = 0.00036787944117144236\n",
      "Evaluation | Accuracy: 97.85 %, Loss: 0.1018\n",
      "Epoch [13/70], Step [100/600], CE_loss: 0.1954, loss: 0.1954\n",
      "Epoch [13/70], Step [200/600], CE_loss: 0.1366, loss: 0.1366\n",
      "Epoch [13/70], Step [300/600], CE_loss: 0.1158, loss: 0.1158\n",
      "Epoch [13/70], Step [400/600], CE_loss: 0.1505, loss: 0.1505\n",
      "Epoch [13/70], Step [500/600], CE_loss: 0.2713, loss: 0.2713\n",
      "Epoch [13/70], Step [600/600], CE_loss: 0.1122, loss: 0.1122\n",
      "learning rate = 0.0001353352832366127\n",
      "Evaluation | Accuracy: 97.81 %, Loss: 0.1036\n",
      "Epoch [14/70], Step [100/600], CE_loss: 0.1908, loss: 0.1908\n",
      "Epoch [14/70], Step [200/600], CE_loss: 0.1417, loss: 0.1417\n",
      "Epoch [14/70], Step [300/600], CE_loss: 0.0408, loss: 0.0408\n",
      "Epoch [14/70], Step [400/600], CE_loss: 0.0785, loss: 0.0785\n",
      "Epoch [14/70], Step [500/600], CE_loss: 0.1495, loss: 0.1495\n",
      "Epoch [14/70], Step [600/600], CE_loss: 0.1503, loss: 0.1503\n",
      "learning rate = 0.0001353352832366127\n",
      "Evaluation | Accuracy: 98.26 %, Loss: 0.0799\n",
      "Epoch [15/70], Step [100/600], CE_loss: 0.0719, loss: 0.0719\n",
      "Epoch [15/70], Step [200/600], CE_loss: 0.2444, loss: 0.2444\n",
      "Epoch [15/70], Step [300/600], CE_loss: 0.0775, loss: 0.0775\n",
      "Epoch [15/70], Step [400/600], CE_loss: 0.1203, loss: 0.1203\n",
      "Epoch [15/70], Step [500/600], CE_loss: 0.0920, loss: 0.0920\n",
      "Epoch [15/70], Step [600/600], CE_loss: 0.2371, loss: 0.2371\n",
      "learning rate = 0.0001353352832366127\n",
      "Evaluation | Accuracy: 98.12 %, Loss: 0.0793\n",
      "Epoch [16/70], Step [100/600], CE_loss: 0.0690, loss: 0.0690\n",
      "Epoch [16/70], Step [200/600], CE_loss: 0.1125, loss: 0.1125\n",
      "Epoch [16/70], Step [300/600], CE_loss: 0.0445, loss: 0.0445\n",
      "Epoch [16/70], Step [400/600], CE_loss: 0.1859, loss: 0.1859\n",
      "Epoch [16/70], Step [500/600], CE_loss: 0.2464, loss: 0.2464\n",
      "Epoch [16/70], Step [600/600], CE_loss: 0.0905, loss: 0.0905\n",
      "learning rate = 4.9787068367863945e-05\n",
      "Evaluation | Accuracy: 98.19 %, Loss: 0.0800\n",
      "Epoch [17/70], Step [100/600], CE_loss: 0.0638, loss: 0.0638\n",
      "Epoch [17/70], Step [200/600], CE_loss: 0.1396, loss: 0.1396\n",
      "Epoch [17/70], Step [300/600], CE_loss: 0.0756, loss: 0.0756\n",
      "Epoch [17/70], Step [400/600], CE_loss: 0.1392, loss: 0.1392\n",
      "Epoch [17/70], Step [500/600], CE_loss: 0.0699, loss: 0.0699\n",
      "Epoch [17/70], Step [600/600], CE_loss: 0.1108, loss: 0.1108\n",
      "learning rate = 4.9787068367863945e-05\n",
      "Evaluation | Accuracy: 98.43 %, Loss: 0.0711\n",
      "Epoch [18/70], Step [100/600], CE_loss: 0.1496, loss: 0.1496\n",
      "Epoch [18/70], Step [200/600], CE_loss: 0.0580, loss: 0.0580\n",
      "Epoch [18/70], Step [300/600], CE_loss: 0.0704, loss: 0.0704\n",
      "Epoch [18/70], Step [400/600], CE_loss: 0.1677, loss: 0.1677\n",
      "Epoch [18/70], Step [500/600], CE_loss: 0.0955, loss: 0.0955\n",
      "Epoch [18/70], Step [600/600], CE_loss: 0.1294, loss: 0.1294\n",
      "learning rate = 4.9787068367863945e-05\n",
      "Evaluation | Accuracy: 98.49 %, Loss: 0.0699\n",
      "Epoch [19/70], Step [100/600], CE_loss: 0.2059, loss: 0.2059\n",
      "Epoch [19/70], Step [200/600], CE_loss: 0.0323, loss: 0.0323\n",
      "Epoch [19/70], Step [300/600], CE_loss: 0.1281, loss: 0.1281\n",
      "Epoch [19/70], Step [400/600], CE_loss: 0.0731, loss: 0.0731\n",
      "Epoch [19/70], Step [500/600], CE_loss: 0.1136, loss: 0.1136\n",
      "Epoch [19/70], Step [600/600], CE_loss: 0.0335, loss: 0.0335\n",
      "learning rate = 1.831563888873418e-05\n",
      "Evaluation | Accuracy: 98.41 %, Loss: 0.0703\n",
      "Epoch [20/70], Step [100/600], CE_loss: 0.0341, loss: 0.0341\n",
      "Epoch [20/70], Step [200/600], CE_loss: 0.0721, loss: 0.0721\n",
      "Epoch [20/70], Step [300/600], CE_loss: 0.0777, loss: 0.0777\n",
      "Epoch [20/70], Step [400/600], CE_loss: 0.0608, loss: 0.0608\n",
      "Epoch [20/70], Step [500/600], CE_loss: 0.1336, loss: 0.1336\n",
      "Epoch [20/70], Step [600/600], CE_loss: 0.1602, loss: 0.1602\n",
      "learning rate = 3e-05\n",
      "Evaluation | Accuracy: 98.49 %, Loss: 0.0689\n",
      "Epoch [21/70], Step [100/600], CE_loss: 0.0821, loss: 0.0821\n",
      "Epoch [21/70], Step [200/600], CE_loss: 0.2028, loss: 0.2028\n",
      "Epoch [21/70], Step [300/600], CE_loss: 0.1135, loss: 0.1135\n",
      "Epoch [21/70], Step [400/600], CE_loss: 0.1017, loss: 0.1017\n",
      "Epoch [21/70], Step [500/600], CE_loss: 0.1124, loss: 0.1124\n",
      "Epoch [21/70], Step [600/600], CE_loss: 0.1558, loss: 0.1558\n",
      "learning rate = 3e-05\n",
      "Evaluation | Accuracy: 98.51 %, Loss: 0.0673\n",
      "Epoch [22/70], Step [100/600], CE_loss: 0.0469, loss: 0.0469\n",
      "Epoch [22/70], Step [200/600], CE_loss: 0.0278, loss: 0.0278\n",
      "Epoch [22/70], Step [300/600], CE_loss: 0.0530, loss: 0.0530\n",
      "Epoch [22/70], Step [400/600], CE_loss: 0.0755, loss: 0.0755\n",
      "Epoch [22/70], Step [500/600], CE_loss: 0.0363, loss: 0.0363\n",
      "Epoch [22/70], Step [600/600], CE_loss: 0.0760, loss: 0.0760\n",
      "learning rate = 3e-05\n",
      "Evaluation | Accuracy: 98.55 %, Loss: 0.0668\n",
      "Epoch [23/70], Step [100/600], CE_loss: 0.1112, loss: 0.1112\n",
      "Epoch [23/70], Step [200/600], CE_loss: 0.1087, loss: 0.1087\n",
      "Epoch [23/70], Step [300/600], CE_loss: 0.1314, loss: 0.1314\n",
      "Epoch [23/70], Step [400/600], CE_loss: 0.0359, loss: 0.0359\n",
      "Epoch [23/70], Step [500/600], CE_loss: 0.1886, loss: 0.1886\n",
      "Epoch [23/70], Step [600/600], CE_loss: 0.1777, loss: 0.1777\n",
      "learning rate = 3e-05\n",
      "Evaluation | Accuracy: 98.47 %, Loss: 0.0690\n",
      "Epoch [24/70], Step [100/600], CE_loss: 0.0834, loss: 0.0834\n",
      "Epoch [24/70], Step [200/600], CE_loss: 0.0967, loss: 0.0967\n",
      "Epoch [24/70], Step [300/600], CE_loss: 0.1045, loss: 0.1045\n",
      "Epoch [24/70], Step [400/600], CE_loss: 0.1365, loss: 0.1365\n",
      "Epoch [24/70], Step [500/600], CE_loss: 0.2219, loss: 0.2219\n",
      "Epoch [24/70], Step [600/600], CE_loss: 0.0683, loss: 0.0683\n",
      "learning rate = 3e-05\n",
      "Evaluation | Accuracy: 98.44 %, Loss: 0.0683\n",
      "Epoch [25/70], Step [100/600], CE_loss: 0.0825, loss: 0.0825\n",
      "Epoch [25/70], Step [200/600], CE_loss: 0.0794, loss: 0.0794\n",
      "Epoch [25/70], Step [300/600], CE_loss: 0.1157, loss: 0.1157\n",
      "Epoch [25/70], Step [400/600], CE_loss: 0.0849, loss: 0.0849\n",
      "Epoch [25/70], Step [500/600], CE_loss: 0.1076, loss: 0.1076\n",
      "Epoch [25/70], Step [600/600], CE_loss: 0.0884, loss: 0.0884\n",
      "learning rate = 3e-05\n",
      "Evaluation | Accuracy: 98.53 %, Loss: 0.0678\n",
      "Epoch [26/70], Step [100/600], CE_loss: 0.0635, loss: 0.0635\n",
      "Epoch [26/70], Step [200/600], CE_loss: 0.1909, loss: 0.1909\n",
      "Epoch [26/70], Step [300/600], CE_loss: 0.1221, loss: 0.1221\n",
      "Epoch [26/70], Step [400/600], CE_loss: 0.0626, loss: 0.0626\n",
      "Epoch [26/70], Step [500/600], CE_loss: 0.0858, loss: 0.0858\n",
      "Epoch [26/70], Step [600/600], CE_loss: 0.0804, loss: 0.0804\n",
      "learning rate = 3e-05\n",
      "Evaluation | Accuracy: 98.39 %, Loss: 0.0685\n",
      "Epoch [27/70], Step [100/600], CE_loss: 0.0683, loss: 0.0683\n",
      "Epoch [27/70], Step [200/600], CE_loss: 0.1077, loss: 0.1077\n",
      "Epoch [27/70], Step [300/600], CE_loss: 0.0271, loss: 0.0271\n",
      "Epoch [27/70], Step [400/600], CE_loss: 0.0656, loss: 0.0656\n",
      "Epoch [27/70], Step [500/600], CE_loss: 0.0611, loss: 0.0611\n",
      "Epoch [27/70], Step [600/600], CE_loss: 0.1204, loss: 0.1204\n",
      "learning rate = 3e-05\n",
      "Evaluation | Accuracy: 98.46 %, Loss: 0.0679\n",
      "Epoch [28/70], Step [100/600], CE_loss: 0.1084, loss: 0.1084\n",
      "Epoch [28/70], Step [200/600], CE_loss: 0.0788, loss: 0.0788\n",
      "Epoch [28/70], Step [300/600], CE_loss: 0.1780, loss: 0.1780\n",
      "Epoch [28/70], Step [400/600], CE_loss: 0.1451, loss: 0.1451\n",
      "Epoch [28/70], Step [500/600], CE_loss: 0.1103, loss: 0.1103\n",
      "Epoch [28/70], Step [600/600], CE_loss: 0.1037, loss: 0.1037\n",
      "learning rate = 3e-05\n",
      "Evaluation | Accuracy: 98.50 %, Loss: 0.0680\n",
      "Epoch [29/70], Step [100/600], CE_loss: 0.0772, loss: 0.0772\n",
      "Epoch [29/70], Step [200/600], CE_loss: 0.0708, loss: 0.0708\n",
      "Epoch [29/70], Step [300/600], CE_loss: 0.1396, loss: 0.1396\n",
      "Epoch [29/70], Step [400/600], CE_loss: 0.0754, loss: 0.0754\n",
      "Epoch [29/70], Step [500/600], CE_loss: 0.0596, loss: 0.0596\n",
      "Epoch [29/70], Step [600/600], CE_loss: 0.0396, loss: 0.0396\n",
      "learning rate = 3e-05\n",
      "Evaluation | Accuracy: 98.50 %, Loss: 0.0673\n",
      "Epoch [30/70], Step [100/600], CE_loss: 0.0552, loss: 0.0552\n",
      "Epoch [30/70], Step [200/600], CE_loss: 0.0965, loss: 0.0965\n",
      "Epoch [30/70], Step [300/600], CE_loss: 0.0477, loss: 0.0477\n",
      "Epoch [30/70], Step [400/600], CE_loss: 0.0687, loss: 0.0687\n",
      "Epoch [30/70], Step [500/600], CE_loss: 0.1585, loss: 0.1585\n",
      "Epoch [30/70], Step [600/600], CE_loss: 0.1593, loss: 0.1593\n",
      "learning rate = 3e-05\n",
      "Evaluation | Accuracy: 98.46 %, Loss: 0.0681\n",
      "Epoch [31/70], Step [100/600], CE_loss: 0.0266, loss: 0.0266\n",
      "Epoch [31/70], Step [200/600], CE_loss: 0.0694, loss: 0.0694\n",
      "Epoch [31/70], Step [300/600], CE_loss: 0.0318, loss: 0.0318\n",
      "Epoch [31/70], Step [400/600], CE_loss: 0.1132, loss: 0.1132\n",
      "Epoch [31/70], Step [500/600], CE_loss: 0.0724, loss: 0.0724\n",
      "Epoch [31/70], Step [600/600], CE_loss: 0.1564, loss: 0.1564\n",
      "learning rate = 3e-05\n",
      "Evaluation | Accuracy: 98.45 %, Loss: 0.0667\n",
      "Epoch [32/70], Step [100/600], CE_loss: 0.0959, loss: 0.0959\n",
      "Epoch [32/70], Step [200/600], CE_loss: 0.0885, loss: 0.0885\n",
      "Epoch [32/70], Step [300/600], CE_loss: 0.1825, loss: 0.1825\n",
      "Epoch [32/70], Step [400/600], CE_loss: 0.1090, loss: 0.1090\n",
      "Epoch [32/70], Step [500/600], CE_loss: 0.1709, loss: 0.1709\n",
      "Epoch [32/70], Step [600/600], CE_loss: 0.1286, loss: 0.1286\n",
      "learning rate = 3e-05\n",
      "Evaluation | Accuracy: 98.52 %, Loss: 0.0662\n",
      "Epoch [33/70], Step [100/600], CE_loss: 0.0618, loss: 0.0618\n",
      "Epoch [33/70], Step [200/600], CE_loss: 0.1351, loss: 0.1351\n",
      "Epoch [33/70], Step [300/600], CE_loss: 0.0543, loss: 0.0543\n",
      "Epoch [33/70], Step [400/600], CE_loss: 0.0478, loss: 0.0478\n",
      "Epoch [33/70], Step [500/600], CE_loss: 0.0587, loss: 0.0587\n",
      "Epoch [33/70], Step [600/600], CE_loss: 0.0589, loss: 0.0589\n",
      "learning rate = 3e-05\n",
      "Evaluation | Accuracy: 98.53 %, Loss: 0.0659\n",
      "Epoch [34/70], Step [100/600], CE_loss: 0.1940, loss: 0.1940\n",
      "Epoch [34/70], Step [200/600], CE_loss: 0.0161, loss: 0.0161\n",
      "Epoch [34/70], Step [300/600], CE_loss: 0.0845, loss: 0.0845\n",
      "Epoch [34/70], Step [400/600], CE_loss: 0.0706, loss: 0.0706\n",
      "Epoch [34/70], Step [500/600], CE_loss: 0.0476, loss: 0.0476\n",
      "Epoch [34/70], Step [600/600], CE_loss: 0.1522, loss: 0.1522\n",
      "learning rate = 3e-05\n",
      "Evaluation | Accuracy: 98.58 %, Loss: 0.0649\n",
      "Epoch [35/70], Step [100/600], CE_loss: 0.0411, loss: 0.0411\n",
      "Epoch [35/70], Step [200/600], CE_loss: 0.0585, loss: 0.0585\n",
      "Epoch [35/70], Step [300/600], CE_loss: 0.0592, loss: 0.0592\n",
      "Epoch [35/70], Step [400/600], CE_loss: 0.0888, loss: 0.0888\n",
      "Epoch [35/70], Step [500/600], CE_loss: 0.1943, loss: 0.1943\n",
      "Epoch [35/70], Step [600/600], CE_loss: 0.0477, loss: 0.0477\n",
      "learning rate = 3e-05\n",
      "Evaluation | Accuracy: 98.49 %, Loss: 0.0658\n",
      "Epoch [36/70], Step [100/600], CE_loss: 0.0922, loss: 0.0922\n",
      "Epoch [36/70], Step [200/600], CE_loss: 0.0891, loss: 0.0891\n",
      "Epoch [36/70], Step [300/600], CE_loss: 0.1117, loss: 0.1117\n",
      "Epoch [36/70], Step [400/600], CE_loss: 0.0690, loss: 0.0690\n",
      "Epoch [36/70], Step [500/600], CE_loss: 0.0988, loss: 0.0988\n",
      "Epoch [36/70], Step [600/600], CE_loss: 0.1096, loss: 0.1096\n",
      "learning rate = 3e-05\n",
      "Evaluation | Accuracy: 98.49 %, Loss: 0.0661\n",
      "Epoch [37/70], Step [100/600], CE_loss: 0.0645, loss: 0.0645\n",
      "Epoch [37/70], Step [200/600], CE_loss: 0.2121, loss: 0.2121\n",
      "Epoch [37/70], Step [300/600], CE_loss: 0.0575, loss: 0.0575\n",
      "Epoch [37/70], Step [400/600], CE_loss: 0.1084, loss: 0.1084\n",
      "Epoch [37/70], Step [500/600], CE_loss: 0.1081, loss: 0.1081\n",
      "Epoch [37/70], Step [600/600], CE_loss: 0.0553, loss: 0.0553\n",
      "learning rate = 3e-05\n",
      "Evaluation | Accuracy: 98.53 %, Loss: 0.0632\n",
      "Epoch [38/70], Step [100/600], CE_loss: 0.0403, loss: 0.0403\n",
      "Epoch [38/70], Step [200/600], CE_loss: 0.0774, loss: 0.0774\n",
      "Epoch [38/70], Step [300/600], CE_loss: 0.0775, loss: 0.0775\n",
      "Epoch [38/70], Step [400/600], CE_loss: 0.0169, loss: 0.0169\n",
      "Epoch [38/70], Step [500/600], CE_loss: 0.0434, loss: 0.0434\n",
      "Epoch [38/70], Step [600/600], CE_loss: 0.0297, loss: 0.0297\n",
      "learning rate = 3e-05\n",
      "Evaluation | Accuracy: 98.48 %, Loss: 0.0663\n",
      "Epoch [39/70], Step [100/600], CE_loss: 0.0464, loss: 0.0464\n",
      "Epoch [39/70], Step [200/600], CE_loss: 0.1224, loss: 0.1224\n",
      "Epoch [39/70], Step [300/600], CE_loss: 0.0437, loss: 0.0437\n",
      "Epoch [39/70], Step [400/600], CE_loss: 0.0989, loss: 0.0989\n",
      "Epoch [39/70], Step [500/600], CE_loss: 0.0767, loss: 0.0767\n",
      "Epoch [39/70], Step [600/600], CE_loss: 0.1093, loss: 0.1093\n",
      "learning rate = 3e-05\n",
      "Evaluation | Accuracy: 98.54 %, Loss: 0.0642\n",
      "Epoch [40/70], Step [100/600], CE_loss: 0.1064, loss: 0.1064\n",
      "Epoch [40/70], Step [200/600], CE_loss: 0.0307, loss: 0.0307\n",
      "Epoch [40/70], Step [300/600], CE_loss: 0.0752, loss: 0.0752\n",
      "Epoch [40/70], Step [400/600], CE_loss: 0.1475, loss: 0.1475\n",
      "Epoch [40/70], Step [500/600], CE_loss: 0.0928, loss: 0.0928\n",
      "Epoch [40/70], Step [600/600], CE_loss: 0.0641, loss: 0.0641\n",
      "learning rate = 3e-05\n",
      "Evaluation | Accuracy: 98.49 %, Loss: 0.0658\n",
      "Epoch [41/70], Step [100/600], CE_loss: 0.1199, loss: 0.1199\n",
      "Epoch [41/70], Step [200/600], CE_loss: 0.0481, loss: 0.0481\n",
      "Epoch [41/70], Step [300/600], CE_loss: 0.0861, loss: 0.0861\n",
      "Epoch [41/70], Step [400/600], CE_loss: 0.2250, loss: 0.2250\n",
      "Epoch [41/70], Step [500/600], CE_loss: 0.0454, loss: 0.0454\n",
      "Epoch [41/70], Step [600/600], CE_loss: 0.0849, loss: 0.0849\n",
      "learning rate = 3e-05\n",
      "Evaluation | Accuracy: 98.53 %, Loss: 0.0637\n",
      "Epoch [42/70], Step [100/600], CE_loss: 0.0291, loss: 0.0291\n",
      "Epoch [42/70], Step [200/600], CE_loss: 0.0653, loss: 0.0653\n",
      "Epoch [42/70], Step [300/600], CE_loss: 0.0277, loss: 0.0277\n",
      "Epoch [42/70], Step [400/600], CE_loss: 0.0605, loss: 0.0605\n",
      "Epoch [42/70], Step [500/600], CE_loss: 0.1612, loss: 0.1612\n",
      "Epoch [42/70], Step [600/600], CE_loss: 0.1070, loss: 0.1070\n",
      "learning rate = 3e-05\n",
      "Evaluation | Accuracy: 98.53 %, Loss: 0.0642\n",
      "Epoch [43/70], Step [100/600], CE_loss: 0.1182, loss: 0.1182\n",
      "Epoch [43/70], Step [200/600], CE_loss: 0.0279, loss: 0.0279\n",
      "Epoch [43/70], Step [300/600], CE_loss: 0.0598, loss: 0.0598\n",
      "Epoch [43/70], Step [400/600], CE_loss: 0.0465, loss: 0.0465\n",
      "Epoch [43/70], Step [500/600], CE_loss: 0.1528, loss: 0.1528\n",
      "Epoch [43/70], Step [600/600], CE_loss: 0.0841, loss: 0.0841\n",
      "learning rate = 3e-05\n",
      "Evaluation | Accuracy: 98.52 %, Loss: 0.0637\n",
      "Epoch [44/70], Step [100/600], CE_loss: 0.0780, loss: 0.0780\n",
      "Epoch [44/70], Step [200/600], CE_loss: 0.0585, loss: 0.0585\n",
      "Epoch [44/70], Step [300/600], CE_loss: 0.0746, loss: 0.0746\n",
      "Epoch [44/70], Step [400/600], CE_loss: 0.0479, loss: 0.0479\n",
      "Epoch [44/70], Step [500/600], CE_loss: 0.1587, loss: 0.1587\n",
      "Epoch [44/70], Step [600/600], CE_loss: 0.0603, loss: 0.0603\n",
      "learning rate = 3e-05\n",
      "Evaluation | Accuracy: 98.55 %, Loss: 0.0637\n",
      "Epoch [45/70], Step [100/600], CE_loss: 0.0657, loss: 0.0657\n",
      "Epoch [45/70], Step [200/600], CE_loss: 0.0673, loss: 0.0673\n",
      "Epoch [45/70], Step [300/600], CE_loss: 0.1213, loss: 0.1213\n",
      "Epoch [45/70], Step [400/600], CE_loss: 0.1046, loss: 0.1046\n",
      "Epoch [45/70], Step [500/600], CE_loss: 0.1143, loss: 0.1143\n",
      "Epoch [45/70], Step [600/600], CE_loss: 0.0735, loss: 0.0735\n",
      "learning rate = 3e-05\n",
      "Evaluation | Accuracy: 98.56 %, Loss: 0.0626\n",
      "Epoch [46/70], Step [100/600], CE_loss: 0.0585, loss: 0.0585\n",
      "Epoch [46/70], Step [200/600], CE_loss: 0.0858, loss: 0.0858\n",
      "Epoch [46/70], Step [300/600], CE_loss: 0.0290, loss: 0.0290\n",
      "Epoch [46/70], Step [400/600], CE_loss: 0.1044, loss: 0.1044\n",
      "Epoch [46/70], Step [500/600], CE_loss: 0.0356, loss: 0.0356\n",
      "Epoch [46/70], Step [600/600], CE_loss: 0.0880, loss: 0.0880\n",
      "learning rate = 3e-05\n",
      "Evaluation | Accuracy: 98.46 %, Loss: 0.0638\n",
      "Epoch [47/70], Step [100/600], CE_loss: 0.0917, loss: 0.0917\n",
      "Epoch [47/70], Step [200/600], CE_loss: 0.0566, loss: 0.0566\n",
      "Epoch [47/70], Step [300/600], CE_loss: 0.0523, loss: 0.0523\n",
      "Epoch [47/70], Step [400/600], CE_loss: 0.1210, loss: 0.1210\n",
      "Epoch [47/70], Step [500/600], CE_loss: 0.1249, loss: 0.1249\n",
      "Epoch [47/70], Step [600/600], CE_loss: 0.1310, loss: 0.1310\n",
      "learning rate = 3e-05\n",
      "Evaluation | Accuracy: 98.48 %, Loss: 0.0636\n",
      "Epoch [48/70], Step [100/600], CE_loss: 0.0499, loss: 0.0499\n",
      "Epoch [48/70], Step [200/600], CE_loss: 0.0639, loss: 0.0639\n",
      "Epoch [48/70], Step [300/600], CE_loss: 0.0762, loss: 0.0762\n",
      "Epoch [48/70], Step [400/600], CE_loss: 0.0873, loss: 0.0873\n",
      "Epoch [48/70], Step [500/600], CE_loss: 0.0404, loss: 0.0404\n",
      "Epoch [48/70], Step [600/600], CE_loss: 0.0760, loss: 0.0760\n",
      "learning rate = 3e-05\n",
      "Evaluation | Accuracy: 98.59 %, Loss: 0.0644\n",
      "Epoch [49/70], Step [100/600], CE_loss: 0.0450, loss: 0.0450\n",
      "Epoch [49/70], Step [200/600], CE_loss: 0.0314, loss: 0.0314\n",
      "Epoch [49/70], Step [300/600], CE_loss: 0.0498, loss: 0.0498\n",
      "Epoch [49/70], Step [400/600], CE_loss: 0.1791, loss: 0.1791\n",
      "Epoch [49/70], Step [500/600], CE_loss: 0.0501, loss: 0.0501\n",
      "Epoch [49/70], Step [600/600], CE_loss: 0.1129, loss: 0.1129\n",
      "learning rate = 3e-05\n",
      "Evaluation | Accuracy: 98.58 %, Loss: 0.0634\n",
      "Epoch [50/70], Step [100/600], CE_loss: 0.0411, loss: 0.0411\n",
      "Epoch [50/70], Step [200/600], CE_loss: 0.0478, loss: 0.0478\n",
      "Epoch [50/70], Step [300/600], CE_loss: 0.0878, loss: 0.0878\n",
      "Epoch [50/70], Step [400/600], CE_loss: 0.0819, loss: 0.0819\n",
      "Epoch [50/70], Step [500/600], CE_loss: 0.1134, loss: 0.1134\n",
      "Epoch [50/70], Step [600/600], CE_loss: 0.0661, loss: 0.0661\n",
      "learning rate = 3e-05\n",
      "Evaluation | Accuracy: 98.51 %, Loss: 0.0652\n",
      "Epoch [51/70], Step [100/600], CE_loss: 0.0923, loss: 0.0923\n",
      "Epoch [51/70], Step [200/600], CE_loss: 0.0755, loss: 0.0755\n",
      "Epoch [51/70], Step [300/600], CE_loss: 0.0426, loss: 0.0426\n",
      "Epoch [51/70], Step [400/600], CE_loss: 0.1205, loss: 0.1205\n",
      "Epoch [51/70], Step [500/600], CE_loss: 0.0921, loss: 0.0921\n",
      "Epoch [51/70], Step [600/600], CE_loss: 0.0967, loss: 0.0967\n",
      "learning rate = 3e-05\n",
      "Evaluation | Accuracy: 98.56 %, Loss: 0.0633\n",
      "Epoch [52/70], Step [100/600], CE_loss: 0.0819, loss: 0.0819\n",
      "Epoch [52/70], Step [200/600], CE_loss: 0.0924, loss: 0.0924\n",
      "Epoch [52/70], Step [300/600], CE_loss: 0.0442, loss: 0.0442\n",
      "Epoch [52/70], Step [400/600], CE_loss: 0.0613, loss: 0.0613\n",
      "Epoch [52/70], Step [500/600], CE_loss: 0.0702, loss: 0.0702\n",
      "Epoch [52/70], Step [600/600], CE_loss: 0.0465, loss: 0.0465\n",
      "learning rate = 3e-05\n",
      "Evaluation | Accuracy: 98.63 %, Loss: 0.0630\n",
      "Epoch [53/70], Step [100/600], CE_loss: 0.0433, loss: 0.0433\n",
      "Epoch [53/70], Step [200/600], CE_loss: 0.0681, loss: 0.0681\n",
      "Epoch [53/70], Step [300/600], CE_loss: 0.0911, loss: 0.0911\n",
      "Epoch [53/70], Step [400/600], CE_loss: 0.1483, loss: 0.1483\n",
      "Epoch [53/70], Step [500/600], CE_loss: 0.1336, loss: 0.1336\n",
      "Epoch [53/70], Step [600/600], CE_loss: 0.0751, loss: 0.0751\n",
      "learning rate = 3e-05\n",
      "Evaluation | Accuracy: 98.63 %, Loss: 0.0620\n",
      "Epoch [54/70], Step [100/600], CE_loss: 0.1040, loss: 0.1040\n",
      "Epoch [54/70], Step [200/600], CE_loss: 0.1248, loss: 0.1248\n",
      "Epoch [54/70], Step [300/600], CE_loss: 0.1459, loss: 0.1459\n",
      "Epoch [54/70], Step [400/600], CE_loss: 0.0462, loss: 0.0462\n",
      "Epoch [54/70], Step [500/600], CE_loss: 0.0618, loss: 0.0618\n",
      "Epoch [54/70], Step [600/600], CE_loss: 0.0892, loss: 0.0892\n",
      "learning rate = 3e-05\n",
      "Evaluation | Accuracy: 98.68 %, Loss: 0.0629\n",
      "Epoch [55/70], Step [100/600], CE_loss: 0.0964, loss: 0.0964\n",
      "Epoch [55/70], Step [200/600], CE_loss: 0.1886, loss: 0.1886\n",
      "Epoch [55/70], Step [300/600], CE_loss: 0.0628, loss: 0.0628\n",
      "Epoch [55/70], Step [400/600], CE_loss: 0.0523, loss: 0.0523\n",
      "Epoch [55/70], Step [500/600], CE_loss: 0.1174, loss: 0.1174\n",
      "Epoch [55/70], Step [600/600], CE_loss: 0.0728, loss: 0.0728\n",
      "learning rate = 3e-05\n",
      "Evaluation | Accuracy: 98.57 %, Loss: 0.0648\n",
      "Epoch [56/70], Step [100/600], CE_loss: 0.0608, loss: 0.0608\n",
      "Epoch [56/70], Step [200/600], CE_loss: 0.0647, loss: 0.0647\n",
      "Epoch [56/70], Step [300/600], CE_loss: 0.0994, loss: 0.0994\n",
      "Epoch [56/70], Step [400/600], CE_loss: 0.0718, loss: 0.0718\n",
      "Epoch [56/70], Step [500/600], CE_loss: 0.1024, loss: 0.1024\n",
      "Epoch [56/70], Step [600/600], CE_loss: 0.0678, loss: 0.0678\n",
      "learning rate = 3e-05\n",
      "Evaluation | Accuracy: 98.66 %, Loss: 0.0631\n",
      "Epoch [57/70], Step [100/600], CE_loss: 0.0982, loss: 0.0982\n",
      "Epoch [57/70], Step [200/600], CE_loss: 0.0971, loss: 0.0971\n",
      "Epoch [57/70], Step [300/600], CE_loss: 0.0471, loss: 0.0471\n",
      "Epoch [57/70], Step [400/600], CE_loss: 0.0832, loss: 0.0832\n",
      "Epoch [57/70], Step [500/600], CE_loss: 0.1454, loss: 0.1454\n",
      "Epoch [57/70], Step [600/600], CE_loss: 0.0594, loss: 0.0594\n",
      "learning rate = 3e-05\n",
      "Evaluation | Accuracy: 98.58 %, Loss: 0.0627\n",
      "Epoch [58/70], Step [100/600], CE_loss: 0.1062, loss: 0.1062\n",
      "Epoch [58/70], Step [200/600], CE_loss: 0.1316, loss: 0.1316\n",
      "Epoch [58/70], Step [300/600], CE_loss: 0.0642, loss: 0.0642\n",
      "Epoch [58/70], Step [400/600], CE_loss: 0.1314, loss: 0.1314\n",
      "Epoch [58/70], Step [500/600], CE_loss: 0.0521, loss: 0.0521\n",
      "Epoch [58/70], Step [600/600], CE_loss: 0.0725, loss: 0.0725\n",
      "learning rate = 3e-05\n",
      "Evaluation | Accuracy: 98.58 %, Loss: 0.0618\n",
      "Epoch [59/70], Step [100/600], CE_loss: 0.0960, loss: 0.0960\n",
      "Epoch [59/70], Step [200/600], CE_loss: 0.0522, loss: 0.0522\n",
      "Epoch [59/70], Step [300/600], CE_loss: 0.1338, loss: 0.1338\n",
      "Epoch [59/70], Step [400/600], CE_loss: 0.1867, loss: 0.1867\n",
      "Epoch [59/70], Step [500/600], CE_loss: 0.0549, loss: 0.0549\n",
      "Epoch [59/70], Step [600/600], CE_loss: 0.0746, loss: 0.0746\n",
      "learning rate = 3e-05\n",
      "Evaluation | Accuracy: 98.59 %, Loss: 0.0633\n",
      "Epoch [60/70], Step [100/600], CE_loss: 0.0440, loss: 0.0440\n",
      "Epoch [60/70], Step [200/600], CE_loss: 0.0174, loss: 0.0174\n",
      "Epoch [60/70], Step [300/600], CE_loss: 0.0550, loss: 0.0550\n",
      "Epoch [60/70], Step [400/600], CE_loss: 0.0228, loss: 0.0228\n",
      "Epoch [60/70], Step [500/600], CE_loss: 0.0755, loss: 0.0755\n",
      "Epoch [60/70], Step [600/600], CE_loss: 0.0700, loss: 0.0700\n",
      "learning rate = 3e-05\n",
      "Evaluation | Accuracy: 98.60 %, Loss: 0.0620\n",
      "Epoch [61/70], Step [100/600], CE_loss: 0.0871, loss: 0.0871\n",
      "Epoch [61/70], Step [200/600], CE_loss: 0.0432, loss: 0.0432\n",
      "Epoch [61/70], Step [300/600], CE_loss: 0.0534, loss: 0.0534\n",
      "Epoch [61/70], Step [400/600], CE_loss: 0.0569, loss: 0.0569\n",
      "Epoch [61/70], Step [500/600], CE_loss: 0.0994, loss: 0.0994\n",
      "Epoch [61/70], Step [600/600], CE_loss: 0.1115, loss: 0.1115\n",
      "learning rate = 3e-05\n",
      "Evaluation | Accuracy: 98.69 %, Loss: 0.0607\n",
      "Epoch [62/70], Step [100/600], CE_loss: 0.0523, loss: 0.0523\n",
      "Epoch [62/70], Step [200/600], CE_loss: 0.1093, loss: 0.1093\n",
      "Epoch [62/70], Step [300/600], CE_loss: 0.0491, loss: 0.0491\n",
      "Epoch [62/70], Step [400/600], CE_loss: 0.0224, loss: 0.0224\n",
      "Epoch [62/70], Step [500/600], CE_loss: 0.0527, loss: 0.0527\n",
      "Epoch [62/70], Step [600/600], CE_loss: 0.1825, loss: 0.1825\n",
      "learning rate = 3e-05\n",
      "Evaluation | Accuracy: 98.66 %, Loss: 0.0609\n",
      "Epoch [63/70], Step [100/600], CE_loss: 0.1689, loss: 0.1689\n",
      "Epoch [63/70], Step [200/600], CE_loss: 0.0140, loss: 0.0140\n",
      "Epoch [63/70], Step [300/600], CE_loss: 0.0518, loss: 0.0518\n",
      "Epoch [63/70], Step [400/600], CE_loss: 0.1344, loss: 0.1344\n",
      "Epoch [63/70], Step [500/600], CE_loss: 0.0822, loss: 0.0822\n",
      "Epoch [63/70], Step [600/600], CE_loss: 0.1188, loss: 0.1188\n",
      "learning rate = 3e-05\n",
      "Evaluation | Accuracy: 98.71 %, Loss: 0.0624\n",
      "Epoch [64/70], Step [100/600], CE_loss: 0.1177, loss: 0.1177\n",
      "Epoch [64/70], Step [200/600], CE_loss: 0.0120, loss: 0.0120\n",
      "Epoch [64/70], Step [300/600], CE_loss: 0.0961, loss: 0.0961\n",
      "Epoch [64/70], Step [400/600], CE_loss: 0.0574, loss: 0.0574\n",
      "Epoch [64/70], Step [500/600], CE_loss: 0.1188, loss: 0.1188\n",
      "Epoch [64/70], Step [600/600], CE_loss: 0.0913, loss: 0.0913\n",
      "learning rate = 3e-05\n",
      "Evaluation | Accuracy: 98.56 %, Loss: 0.0622\n",
      "Epoch [65/70], Step [100/600], CE_loss: 0.0675, loss: 0.0675\n",
      "Epoch [65/70], Step [200/600], CE_loss: 0.0909, loss: 0.0909\n",
      "Epoch [65/70], Step [300/600], CE_loss: 0.0324, loss: 0.0324\n",
      "Epoch [65/70], Step [400/600], CE_loss: 0.0484, loss: 0.0484\n",
      "Epoch [65/70], Step [500/600], CE_loss: 0.0585, loss: 0.0585\n",
      "Epoch [65/70], Step [600/600], CE_loss: 0.1262, loss: 0.1262\n",
      "learning rate = 3e-05\n",
      "Evaluation | Accuracy: 98.69 %, Loss: 0.0609\n",
      "Epoch [66/70], Step [100/600], CE_loss: 0.0377, loss: 0.0377\n",
      "Epoch [66/70], Step [200/600], CE_loss: 0.0922, loss: 0.0922\n",
      "Epoch [66/70], Step [300/600], CE_loss: 0.0787, loss: 0.0787\n",
      "Epoch [66/70], Step [400/600], CE_loss: 0.0821, loss: 0.0821\n",
      "Epoch [66/70], Step [500/600], CE_loss: 0.0264, loss: 0.0264\n",
      "Epoch [66/70], Step [600/600], CE_loss: 0.0391, loss: 0.0391\n",
      "learning rate = 3e-05\n",
      "Evaluation | Accuracy: 98.63 %, Loss: 0.0629\n",
      "Epoch [67/70], Step [100/600], CE_loss: 0.0397, loss: 0.0397\n",
      "Epoch [67/70], Step [200/600], CE_loss: 0.1092, loss: 0.1092\n",
      "Epoch [67/70], Step [300/600], CE_loss: 0.1919, loss: 0.1919\n",
      "Epoch [67/70], Step [400/600], CE_loss: 0.0720, loss: 0.0720\n",
      "Epoch [67/70], Step [500/600], CE_loss: 0.0524, loss: 0.0524\n",
      "Epoch [67/70], Step [600/600], CE_loss: 0.0422, loss: 0.0422\n",
      "learning rate = 3e-05\n",
      "Evaluation | Accuracy: 98.65 %, Loss: 0.0625\n",
      "Epoch [68/70], Step [100/600], CE_loss: 0.0578, loss: 0.0578\n",
      "Epoch [68/70], Step [200/600], CE_loss: 0.0513, loss: 0.0513\n",
      "Epoch [68/70], Step [300/600], CE_loss: 0.1604, loss: 0.1604\n",
      "Epoch [68/70], Step [400/600], CE_loss: 0.0798, loss: 0.0798\n",
      "Epoch [68/70], Step [500/600], CE_loss: 0.0624, loss: 0.0624\n",
      "Epoch [68/70], Step [600/600], CE_loss: 0.0822, loss: 0.0822\n",
      "learning rate = 3e-05\n",
      "Evaluation | Accuracy: 98.69 %, Loss: 0.0615\n",
      "Epoch [69/70], Step [100/600], CE_loss: 0.0606, loss: 0.0606\n",
      "Epoch [69/70], Step [200/600], CE_loss: 0.0547, loss: 0.0547\n",
      "Epoch [69/70], Step [300/600], CE_loss: 0.1396, loss: 0.1396\n",
      "Epoch [69/70], Step [400/600], CE_loss: 0.0461, loss: 0.0461\n",
      "Epoch [69/70], Step [500/600], CE_loss: 0.1249, loss: 0.1249\n",
      "Epoch [69/70], Step [600/600], CE_loss: 0.1034, loss: 0.1034\n",
      "learning rate = 3e-05\n",
      "Evaluation | Accuracy: 98.68 %, Loss: 0.0607\n",
      "Epoch [70/70], Step [100/600], CE_loss: 0.0874, loss: 0.0874\n",
      "Epoch [70/70], Step [200/600], CE_loss: 0.1189, loss: 0.1189\n",
      "Epoch [70/70], Step [300/600], CE_loss: 0.0562, loss: 0.0562\n",
      "Epoch [70/70], Step [400/600], CE_loss: 0.1991, loss: 0.1991\n",
      "Epoch [70/70], Step [500/600], CE_loss: 0.0937, loss: 0.0937\n",
      "Epoch [70/70], Step [600/600], CE_loss: 0.0502, loss: 0.0502\n",
      "learning rate = 3e-05\n",
      "Evaluation | Accuracy: 98.74 %, Loss: 0.0607\n"
     ]
    }
   ],
   "source": [
    "model.fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = 'mnist_l2_d300_input_noise.pt'\n",
    "with open(filename, 'wb') as f:\n",
    "    torch.save(model, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_pretrained('saved_models/mnist_l2_d300_input_noise')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = MLPModel.from_pretrained('saved_models/mnist_l2_d300_input_noise')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation | Accuracy: 98.74 %, Loss: 0.0607\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(98.74, 0.060730554345919924)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.validation()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sparse EigModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "sparse_eigmodel = SparseEigModel(model).to('mps')\n",
    "config = sparse_eigmodel.config\n",
    "config.L1_param = .01\n",
    "config.epochs = 100\n",
    "config.lr = 0.001\n",
    "config.scheduler_epochs = [0, 100, 0]\n",
    "config.scheduler_min_lambda = 0.03\n",
    "config.scheduler_steps_per = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation | Accuracy: 98.74 %, Loss: 0.0607\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(98.74, 0.06073052446042084)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sparse_eigmodel.set_dataset()\n",
    "sparse_eigmodel.validation()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "STAGE:2024-06-06 11:29:57 99544:67336973 ActivityProfilerController.cpp:314] Completed Stage: Warm Up\n",
      "[W CPUAllocator.cpp:235] Memory block of unknown size was allocated before the profiling started, profiler results will not include the deallocation event\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation | Accuracy: 98.74 %, Loss: 0.0607\n",
      "Epoch [1/100], Step [100/600], CE_loss: 0.0341, L1: 8.7358, L0: 704670.3125, loss: 0.1214\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "STAGE:2024-06-06 11:32:51 99544:67336973 ActivityProfilerController.cpp:320] Completed Stage: Collection\n",
      "STAGE:2024-06-06 11:32:51 99544:67336973 ActivityProfilerController.cpp:324] Completed Stage: Post Processing\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43msparse_eigmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Library/CloudStorage/GoogleDrive-michaelttpearce@gmail.com/My Drive/AI Safety/Bilinear Features/bilinear/model.py:128\u001b[0m, in \u001b[0;36mBaseModel.fit\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    126\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, (inputs, labels) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrain_loader):\n\u001b[1;32m    127\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrain()\n\u001b[0;32m--> 128\u001b[0m     inputs, labels \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtransform_inputs\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    130\u001b[0m     \u001b[38;5;66;03m# Forward pass\u001b[39;00m\n\u001b[1;32m    131\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mforward(inputs)\n",
      "File \u001b[0;32m~/Library/CloudStorage/GoogleDrive-michaelttpearce@gmail.com/My Drive/AI Safety/Bilinear Features/bilinear/model.py:92\u001b[0m, in \u001b[0;36mBaseModel.transform_inputs\u001b[0;34m(self, inputs, labels)\u001b[0m\n\u001b[1;32m     90\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mtransform_inputs\u001b[39m(\u001b[38;5;28mself\u001b[39m, inputs, labels):\n\u001b[1;32m     91\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mdataset \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmnist\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[0;32m---> 92\u001b[0m         inputs \u001b[38;5;241m=\u001b[39m \u001b[43minputs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreshape\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshape\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     93\u001b[0m         labels \u001b[38;5;241m=\u001b[39m labels\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice)\n\u001b[1;32m     94\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m inputs, labels\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "sparse_eigmodel.fit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EigModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[-5.0788e-02,  8.5604e-02,  1.3789e-03,  ...,  1.6140e+00,\n",
       "            1.5148e+00,  9.4066e-02],\n",
       "          [ 1.3883e+00,  1.3465e+00, -2.0490e-01,  ..., -1.8864e+00,\n",
       "            1.4810e+00, -1.4876e-01],\n",
       "          [ 6.2999e-01,  1.5777e+00, -1.0477e+00,  ...,  3.4320e+00,\n",
       "            1.4238e+00, -1.4795e+00],\n",
       "          ...,\n",
       "          [ 6.4850e-02, -1.0238e-01,  9.4494e-01,  ...,  3.6061e-01,\n",
       "           -2.5401e-01,  3.3656e-01],\n",
       "          [-1.6221e+00,  1.8498e-01,  1.9064e-01,  ..., -6.0732e-01,\n",
       "            3.7124e-01, -1.1240e-01],\n",
       "          [ 3.1008e-01, -1.2885e+00,  8.9986e-01,  ..., -1.7115e-01,\n",
       "            2.3250e-02,  1.4740e+00]],\n",
       "\n",
       "         [[-1.0383e+00, -9.1276e-01, -6.7550e-01,  ..., -4.8075e-01,\n",
       "           -3.6399e-01,  3.0998e-01],\n",
       "          [-1.4370e+00, -6.9716e-01,  1.4595e+00,  ..., -1.6439e+00,\n",
       "           -3.1028e-01, -8.2877e-01],\n",
       "          [ 1.0839e+00, -5.9206e-01, -1.0550e+00,  ..., -1.4885e+00,\n",
       "            5.6290e-01,  7.4722e-01],\n",
       "          ...,\n",
       "          [ 8.1969e-02, -1.3920e-01,  1.0370e-01,  ..., -3.3167e-02,\n",
       "            6.7693e-02,  2.9094e-02],\n",
       "          [-1.3876e-01,  5.4962e-02, -9.0125e-02,  ..., -7.0202e-03,\n",
       "            2.3653e-02, -4.9515e-02],\n",
       "          [-1.5717e-03, -9.8303e-02,  1.2597e-02,  ..., -1.7640e-01,\n",
       "            2.9717e-02,  6.0043e-01]],\n",
       "\n",
       "         [[-3.5278e-01, -1.4189e+00, -4.2875e-01,  ...,  4.5026e-01,\n",
       "            7.5108e-01,  6.1165e-01],\n",
       "          [-3.4752e-01, -8.3543e-01, -5.3737e-01,  ..., -3.1189e-01,\n",
       "           -3.6005e-02,  5.5194e-01],\n",
       "          [-1.4365e+00, -6.6222e-01, -4.0872e-01,  ...,  1.8283e+00,\n",
       "            3.4213e-01, -9.8407e-01],\n",
       "          ...,\n",
       "          [-8.2906e-02,  1.3174e-01, -5.3763e-02,  ..., -1.8498e-01,\n",
       "           -7.3517e-02, -2.5704e-01],\n",
       "          [-1.1254e-01, -2.6225e-01,  1.4134e-01,  ...,  2.1524e-01,\n",
       "           -1.7911e-01, -2.2849e-01],\n",
       "          [ 1.8361e-01, -1.6245e-01,  1.3086e-01,  ..., -9.8679e-02,\n",
       "           -9.2344e-02,  1.6644e+00]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[ 6.1946e-01, -8.5490e-01, -2.0973e+00,  ..., -1.9628e-02,\n",
       "            3.4119e-01,  1.1250e+00],\n",
       "          [-9.9352e-02, -1.8480e+00, -2.8501e-01,  ...,  1.5999e+00,\n",
       "            2.6889e+00, -1.7613e+00],\n",
       "          [ 1.0475e+00, -1.9302e+00, -2.9245e+00,  ...,  3.6335e-01,\n",
       "           -2.9718e-01, -1.1031e+00],\n",
       "          ...,\n",
       "          [ 1.6726e+00,  6.7905e-01,  5.1585e-01,  ..., -2.4347e+00,\n",
       "            1.8827e+00,  4.1059e-01],\n",
       "          [-4.2068e-02, -1.0426e-01,  1.0227e+00,  ...,  5.3210e-01,\n",
       "            2.9556e-01,  4.2930e-02],\n",
       "          [-4.6324e-02,  2.2828e-01,  3.6899e-01,  ...,  7.8280e-02,\n",
       "           -3.2393e-02,  1.0278e+00]],\n",
       "\n",
       "         [[ 7.6163e-01,  1.2665e+00, -1.4900e+00,  ..., -2.6483e-01,\n",
       "           -2.0449e+00,  1.3021e+00],\n",
       "          [-1.3928e+00,  1.9941e-01, -2.0443e-01,  ...,  8.5085e-01,\n",
       "            2.6218e+00,  1.1445e+00],\n",
       "          [ 1.1719e+00,  1.9082e+00, -6.4618e-02,  ..., -9.6802e-01,\n",
       "            6.9391e-01,  1.3329e+00],\n",
       "          ...,\n",
       "          [ 2.5500e-01, -9.5570e-01,  5.4037e-02,  ...,  6.5951e-01,\n",
       "           -1.3362e-01,  1.9676e-01],\n",
       "          [-4.5379e-01, -3.8211e-01, -5.2150e-02,  ..., -1.2606e+00,\n",
       "            6.9953e-01, -7.8086e-02],\n",
       "          [ 1.5167e-01,  4.1517e-01,  1.4808e+00,  ..., -4.0312e-01,\n",
       "           -1.6407e+00,  4.3069e-01]],\n",
       "\n",
       "         [[ 1.8230e+00,  2.2146e-01,  4.6666e-03,  ..., -6.3633e-01,\n",
       "            2.4782e-01,  1.0521e+00],\n",
       "          [-1.2755e+00,  1.5518e+00, -1.7060e+00,  ..., -1.5685e+00,\n",
       "            8.0191e-01, -7.2877e-01],\n",
       "          [ 2.7749e-01, -1.0950e+00,  9.3200e-01,  ...,  1.3457e+00,\n",
       "            1.1465e+00, -1.0421e+00],\n",
       "          ...,\n",
       "          [-4.1581e-02, -1.9771e+00, -3.7913e-01,  ..., -2.3257e-01,\n",
       "           -5.8071e-01,  8.3364e-01],\n",
       "          [ 1.9506e-02,  1.0909e+00,  3.2648e-02,  ..., -8.3178e-01,\n",
       "           -6.8541e-01, -1.4025e-01],\n",
       "          [-2.3582e-01, -1.1793e+00,  1.1282e+00,  ...,  5.9768e-01,\n",
       "            1.7146e+00, -9.6108e-01]]],\n",
       "\n",
       "\n",
       "        [[[-8.6692e-01, -2.1062e+00,  2.0717e-02,  ..., -8.5061e-01,\n",
       "            1.1439e+00, -1.8017e+00],\n",
       "          [ 1.2088e+00,  1.3067e-01,  1.1300e+00,  ...,  9.3889e-01,\n",
       "            1.4297e+00, -1.1476e+00],\n",
       "          [-1.5712e-01,  1.2186e+00,  1.4328e+00,  ..., -1.5731e+00,\n",
       "           -2.7001e-01, -2.3844e-01],\n",
       "          ...,\n",
       "          [ 4.9402e-01, -7.1496e-01, -1.1825e-01,  ..., -8.0003e-01,\n",
       "           -1.1704e+00, -4.3568e-01],\n",
       "          [ 1.6434e-02, -9.2064e-01,  6.0689e-02,  ...,  8.0030e-01,\n",
       "            1.5365e+00,  3.1704e-01],\n",
       "          [ 6.2936e-01, -3.1542e-01,  1.2667e+00,  ...,  3.3445e-01,\n",
       "           -1.0024e-01, -2.1316e+00]],\n",
       "\n",
       "         [[ 3.7135e-02, -1.8620e+00,  7.4735e-01,  ...,  6.2564e-01,\n",
       "           -7.9608e-01,  3.6607e-02],\n",
       "          [-1.2165e+00, -5.2896e-01, -1.1424e+00,  ..., -1.8166e+00,\n",
       "            2.0926e+00,  1.4480e+00],\n",
       "          [-1.1428e+00, -5.1926e-01,  8.6687e-01,  ...,  1.2741e+00,\n",
       "           -1.3433e+00,  2.0728e-01],\n",
       "          ...,\n",
       "          [ 2.8188e-01,  9.4016e-02, -2.5320e-01,  ...,  1.2750e-01,\n",
       "           -3.7633e-01,  1.2321e-01],\n",
       "          [ 1.3470e+00,  4.1771e-01, -2.4429e-01,  ...,  4.6652e-01,\n",
       "           -7.2641e-01, -5.4688e-01],\n",
       "          [-2.4186e-01, -3.5121e-01, -5.8644e-01,  ..., -4.4342e-02,\n",
       "           -1.4022e-01, -5.2249e-01]],\n",
       "\n",
       "         [[ 3.9678e-01, -4.4530e-01,  1.0426e+00,  ...,  2.5772e-01,\n",
       "            1.5822e+00, -1.5802e+00],\n",
       "          [ 2.8338e-01, -5.9699e-01,  2.2736e+00,  ..., -1.3172e+00,\n",
       "           -1.2732e+00,  2.0447e+00],\n",
       "          [ 6.7918e-01, -1.9108e+00,  7.2675e-01,  ...,  3.6510e-01,\n",
       "            2.6448e-01, -1.7429e+00],\n",
       "          ...,\n",
       "          [ 9.5679e-02,  1.7066e-01, -3.1475e-02,  ...,  1.3606e-01,\n",
       "            6.9348e-01,  5.4886e-02],\n",
       "          [ 9.9210e-02, -1.2071e-01, -1.4819e-01,  ...,  1.6999e-01,\n",
       "            1.1854e-01,  5.7353e-02],\n",
       "          [ 1.5573e-01, -1.5413e-01, -1.2268e-01,  ..., -5.5061e-02,\n",
       "            2.2520e-02,  1.1926e+00]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[-1.8693e+00,  1.1602e+00, -2.3825e-01,  ..., -1.2456e+00,\n",
       "           -1.1581e+00, -1.2303e+00],\n",
       "          [-1.0759e+00, -1.6300e+00, -1.8061e+00,  ...,  2.2093e-01,\n",
       "            3.1221e+00,  1.1285e+00],\n",
       "          [ 1.7528e+00,  1.7749e+00,  1.4493e+00,  ..., -3.7019e-01,\n",
       "            1.4252e+00, -1.7557e+00],\n",
       "          ...,\n",
       "          [ 1.4659e-01,  2.3981e-01, -5.9346e-01,  ..., -1.8728e-01,\n",
       "            1.5722e-02,  1.9747e-01],\n",
       "          [-8.3276e-02,  9.9954e-01,  5.7455e-01,  ...,  3.0971e-02,\n",
       "           -2.0736e-05,  1.3573e+00],\n",
       "          [ 6.6114e-01, -1.3795e-01,  1.1211e+00,  ..., -7.2669e-01,\n",
       "            1.0306e+00,  9.9437e-01]],\n",
       "\n",
       "         [[-1.7166e-01,  8.1915e-01,  1.2318e+00,  ..., -2.2533e+00,\n",
       "            7.6065e-01,  1.6065e+00],\n",
       "          [ 1.9706e+00,  1.7423e-01,  6.8794e-01,  ..., -7.6086e-01,\n",
       "            7.9628e-01,  1.2332e-01],\n",
       "          [ 1.4481e+00, -1.5712e+00, -1.6175e+00,  ..., -1.4864e-01,\n",
       "            8.9746e-01, -1.1065e+00],\n",
       "          ...,\n",
       "          [ 2.9657e-01,  9.6166e-01, -1.6383e-01,  ..., -2.2002e-01,\n",
       "           -3.4506e-02, -6.4020e-01],\n",
       "          [-8.1799e-01,  6.0204e-01,  6.6405e-01,  ..., -1.1563e-01,\n",
       "            5.1010e-01,  6.1835e-01],\n",
       "          [ 2.2045e-01, -5.6594e-01, -4.8427e-01,  ..., -1.0363e+00,\n",
       "            2.1730e-01, -1.3316e+00]],\n",
       "\n",
       "         [[-1.0021e-01,  1.5200e+00,  1.0389e+00,  ..., -8.1608e-01,\n",
       "           -1.0085e+00,  1.9907e-01],\n",
       "          [-1.5671e-01, -2.4123e+00,  2.5416e-01,  ...,  1.2040e+00,\n",
       "           -1.1096e+00,  1.0503e+00],\n",
       "          [-9.4362e-01, -9.0422e-01, -3.2142e-01,  ...,  1.7006e+00,\n",
       "            1.4948e+00, -7.6434e-01],\n",
       "          ...,\n",
       "          [ 6.3325e-01, -3.7117e-02, -3.1031e-01,  ..., -1.5281e+00,\n",
       "           -1.5889e-01,  6.8871e-01],\n",
       "          [ 1.6355e-01, -8.6168e-01, -7.8414e-02,  ..., -6.6775e-01,\n",
       "           -9.3277e-01,  4.5387e-01],\n",
       "          [ 4.8341e-01,  6.0551e-01, -3.1723e-02,  ..., -5.7414e-01,\n",
       "            1.1399e-01, -7.5483e-01]]],\n",
       "\n",
       "\n",
       "        [[[-9.8910e-01,  1.1534e+00, -9.0545e-01,  ...,  1.5025e+00,\n",
       "            1.7320e+00, -9.4922e-01],\n",
       "          [ 2.0933e+00, -1.0551e+00, -1.7906e+00,  ...,  2.7828e+00,\n",
       "            1.6616e+00,  1.5501e+00],\n",
       "          [ 1.8639e+00,  2.3757e+00, -9.1197e-01,  ..., -1.1526e+00,\n",
       "            1.2235e+00,  2.0975e+00],\n",
       "          ...,\n",
       "          [ 1.0093e+00, -7.1330e-01, -9.2700e-02,  ..., -9.8277e-01,\n",
       "           -2.8899e-02, -8.3756e-02],\n",
       "          [-1.3495e-01, -5.4869e-02,  1.3482e-01,  ..., -8.3254e-02,\n",
       "            1.1310e-01, -5.3184e-01],\n",
       "          [-6.3868e-01,  7.0634e-01,  3.0613e-01,  ...,  6.5129e-02,\n",
       "           -1.1039e+00,  8.8458e-01]],\n",
       "\n",
       "         [[-1.0568e+00, -9.1000e-02,  1.3121e+00,  ...,  1.8711e+00,\n",
       "            1.0558e+00,  2.1435e+00],\n",
       "          [-1.7235e+00,  1.1137e+00, -6.4158e-01,  ..., -1.2361e+00,\n",
       "           -8.4788e-01, -4.3099e-02],\n",
       "          [ 1.2766e+00,  9.6433e-01, -1.9858e+00,  ...,  1.3633e+00,\n",
       "            2.2367e+00,  8.1725e-01],\n",
       "          ...,\n",
       "          [ 6.7311e-01,  3.2197e-01, -3.7737e-01,  ...,  1.2947e-01,\n",
       "            1.1762e-01,  5.0943e-01],\n",
       "          [ 1.4667e-01,  1.1842e-01, -3.0775e-01,  ...,  1.0253e+00,\n",
       "            9.8495e-01, -1.0680e-01],\n",
       "          [ 4.2538e-01,  5.8784e-01,  3.5253e-01,  ...,  1.0960e+00,\n",
       "           -7.3663e-01, -7.8105e-01]],\n",
       "\n",
       "         [[ 6.1900e-01, -3.8873e-02,  6.4662e-02,  ..., -1.6184e+00,\n",
       "            2.1123e+00,  1.8719e+00],\n",
       "          [ 1.2745e+00,  1.5917e+00,  8.0743e-01,  ...,  7.8381e-01,\n",
       "           -5.1500e-01, -8.4514e-01],\n",
       "          [ 1.9385e+00,  1.3638e+00, -8.9918e-01,  ...,  1.3347e+00,\n",
       "            2.6861e+00, -1.5797e+00],\n",
       "          ...,\n",
       "          [ 1.7310e-01,  2.3106e-02,  3.8509e-01,  ...,  2.8953e-01,\n",
       "           -2.0663e-01,  8.1304e-02],\n",
       "          [-8.4289e-02,  2.7600e-01, -3.7737e-01,  ...,  3.9761e-01,\n",
       "           -4.2110e-01, -4.2178e-01],\n",
       "          [-5.9112e-01, -8.7752e-02,  1.0609e-02,  ..., -8.9666e-01,\n",
       "           -3.6551e-01, -7.5222e-01]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[-3.7396e-01, -1.4097e+00, -7.0159e-01,  ...,  1.5119e+00,\n",
       "            5.6082e-01, -1.2633e+00],\n",
       "          [ 6.8875e-01, -8.0993e-01,  5.3786e-01,  ...,  1.5887e+00,\n",
       "           -5.5108e-01, -6.3860e-01],\n",
       "          [-1.1091e+00, -1.1652e+00,  1.7103e+00,  ..., -7.2685e-01,\n",
       "           -3.7712e-01, -2.7957e+00],\n",
       "          ...,\n",
       "          [-1.1555e+00, -5.0049e-02, -2.4590e-01,  ...,  2.2166e+00,\n",
       "            5.7545e-01,  1.3961e-01],\n",
       "          [-3.4605e-01,  1.5506e-01,  1.1062e-01,  ..., -4.7688e-01,\n",
       "           -7.2898e-02,  3.1535e-01],\n",
       "          [ 2.8058e-01,  3.4413e-01, -1.3414e-01,  ...,  2.9813e-01,\n",
       "            5.0889e-01,  3.7520e-01]],\n",
       "\n",
       "         [[ 8.0775e-01, -1.4234e+00,  3.1576e-01,  ...,  1.4723e+00,\n",
       "           -1.0650e+00,  1.0834e+00],\n",
       "          [-1.4792e+00,  2.3264e+00, -2.6536e-03,  ..., -1.2535e+00,\n",
       "           -1.9586e+00, -1.5235e+00],\n",
       "          [-1.2970e+00,  1.4551e+00,  1.4654e+00,  ...,  1.2965e+00,\n",
       "           -1.7282e+00, -9.4274e-01],\n",
       "          ...,\n",
       "          [ 8.9947e-01,  7.8441e-01,  6.3555e-01,  ..., -1.6361e+00,\n",
       "           -1.5075e-01,  3.9757e-01],\n",
       "          [ 2.1515e-01, -1.5286e-01,  5.8799e-01,  ...,  7.5183e-01,\n",
       "           -5.3398e-01,  6.4877e-01],\n",
       "          [-2.2569e-01, -3.3782e-01,  1.3526e-01,  ...,  2.8554e-02,\n",
       "            4.5939e-01, -4.3873e-01]],\n",
       "\n",
       "         [[-1.1476e+00,  5.7684e-01,  2.3428e-01,  ...,  1.2755e+00,\n",
       "            1.2965e+00,  1.7144e+00],\n",
       "          [-5.0621e-01,  1.1766e+00,  7.0515e-02,  ..., -3.7863e-01,\n",
       "            1.4865e+00,  3.7343e-01],\n",
       "          [ 9.3915e-01, -1.1010e+00,  1.0679e+00,  ...,  1.2733e+00,\n",
       "           -1.7797e+00, -1.7956e+00],\n",
       "          ...,\n",
       "          [ 1.2431e-01, -4.0895e-01,  1.1221e-01,  ...,  2.2302e-01,\n",
       "           -1.7992e-02, -1.8107e-01],\n",
       "          [ 1.7153e+00, -3.0037e-01,  2.5445e-02,  ...,  1.3558e-01,\n",
       "           -8.7875e-02, -2.9448e-02],\n",
       "          [ 1.8474e-01,  1.2853e-01, -1.5803e+00,  ..., -2.0906e-01,\n",
       "           -3.0444e-01,  1.2977e+00]]],\n",
       "\n",
       "\n",
       "        ...,\n",
       "\n",
       "\n",
       "        [[[-9.8242e-01,  7.8988e-01, -9.9703e-01,  ...,  1.1443e+00,\n",
       "            8.1643e-01,  7.1386e-01],\n",
       "          [-2.3084e+00,  6.1326e-01, -1.5993e+00,  ..., -1.5680e+00,\n",
       "           -8.1743e-01, -7.5581e-01],\n",
       "          [-8.6742e-01, -8.3888e-01,  1.1996e+00,  ...,  8.6454e-01,\n",
       "            1.7321e+00, -7.8007e-01],\n",
       "          ...,\n",
       "          [ 1.2822e-01, -3.7742e-01, -8.8394e-02,  ...,  5.0128e-04,\n",
       "            2.7966e-01,  2.4029e-01],\n",
       "          [-4.3139e-01, -1.1795e-01, -7.9763e-01,  ...,  8.7583e-01,\n",
       "           -6.8387e-02,  3.4241e-02],\n",
       "          [ 2.0166e+00,  2.2897e-01, -1.1861e+00,  ...,  3.4775e-01,\n",
       "           -8.9779e-01, -7.8626e-01]],\n",
       "\n",
       "         [[ 2.8322e-01,  1.8008e+00, -2.8393e+00,  ...,  7.6705e-04,\n",
       "           -9.7205e-02,  5.8729e-03],\n",
       "          [-1.6596e+00, -1.4080e-01,  3.3293e-02,  ..., -1.4334e+00,\n",
       "           -9.8915e-01,  1.6931e+00],\n",
       "          [-5.0847e-01, -1.3569e+00,  1.4602e+00,  ...,  3.4771e-01,\n",
       "           -5.2659e-01,  2.7488e+00],\n",
       "          ...,\n",
       "          [ 6.4107e-01, -2.9701e-01,  5.8251e-01,  ...,  1.7921e+00,\n",
       "            1.4392e+00,  8.6933e-01],\n",
       "          [-5.1346e-01, -4.4643e-01,  1.5160e-01,  ...,  2.5710e-01,\n",
       "           -2.3320e-01,  1.7830e+00],\n",
       "          [ 1.7431e-01, -7.2939e-01, -5.7657e-02,  ..., -4.0174e-02,\n",
       "            2.4096e-01,  5.5360e-01]],\n",
       "\n",
       "         [[-2.3660e-01, -8.1162e-01, -1.8242e+00,  ..., -1.8666e-02,\n",
       "           -1.5824e+00,  2.2213e-02],\n",
       "          [-1.1973e+00,  1.7301e+00, -1.5011e+00,  ...,  1.4915e+00,\n",
       "           -1.4810e+00,  1.3563e+00],\n",
       "          [ 2.0848e+00, -1.8698e+00, -1.3395e+00,  ...,  3.5445e-01,\n",
       "            5.8023e-01, -5.6503e-01],\n",
       "          ...,\n",
       "          [-1.1480e+00, -6.1468e-01, -7.6529e-01,  ..., -7.2168e-02,\n",
       "            2.5879e-01, -4.7248e-01],\n",
       "          [ 5.2143e-01,  2.9599e-01, -5.3449e-01,  ..., -1.1754e-01,\n",
       "            1.8221e-01,  6.3376e-01],\n",
       "          [ 4.6499e-02,  1.6436e-01, -1.1702e+00,  ..., -5.8676e-02,\n",
       "           -2.1186e-01, -1.9756e-01]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[ 7.3985e-01,  6.5306e-01,  9.3781e-01,  ..., -1.6006e+00,\n",
       "            2.1794e+00, -5.5598e-01],\n",
       "          [ 4.2797e-01,  2.0614e+00,  1.4762e+00,  ..., -1.1603e-01,\n",
       "           -6.9694e-01,  9.8820e-01],\n",
       "          [ 1.6334e+00, -5.8556e-01,  1.0159e+00,  ..., -3.9659e-01,\n",
       "           -6.3164e-02,  4.7126e-01],\n",
       "          ...,\n",
       "          [-2.9337e-01,  2.9556e-01, -7.7059e-02,  ..., -3.0921e-01,\n",
       "           -1.4012e-02,  7.5022e-02],\n",
       "          [ 1.8738e-01,  1.5517e-01, -6.8449e-02,  ..., -1.4947e-01,\n",
       "            2.4217e-01, -2.4090e-01],\n",
       "          [ 1.6403e-01,  1.3585e-01,  8.9465e-03,  ..., -1.0848e-01,\n",
       "            5.9567e-01, -2.0922e-01]],\n",
       "\n",
       "         [[-2.2796e+00, -1.9606e+00,  2.2967e-01,  ..., -9.9813e-01,\n",
       "            3.2300e+00,  1.3894e+00],\n",
       "          [-1.7712e+00, -1.6146e-01, -2.2070e-01,  ...,  1.4705e+00,\n",
       "            1.4679e-01,  2.3077e+00],\n",
       "          [-1.8255e+00,  1.6255e-01,  2.1590e+00,  ...,  1.2191e+00,\n",
       "            1.0435e+00,  1.2714e+00],\n",
       "          ...,\n",
       "          [-1.7046e-01, -3.9545e-02,  8.4347e-01,  ..., -2.8504e-01,\n",
       "           -1.2928e-01, -1.1737e-01],\n",
       "          [-8.6664e-01, -1.3723e+00, -1.9691e-01,  ...,  5.3082e-01,\n",
       "            2.6326e+00, -1.0267e-02],\n",
       "          [ 8.8500e-02,  1.0589e-04,  1.1273e+00,  ...,  7.0326e-02,\n",
       "            1.8128e-02, -1.6674e+00]],\n",
       "\n",
       "         [[ 4.6960e-01,  5.6219e-01,  8.1762e-01,  ..., -7.2612e-01,\n",
       "           -3.4119e-01, -4.9396e-01],\n",
       "          [-2.0314e-01, -2.0985e+00,  2.7559e-01,  ..., -1.3767e+00,\n",
       "           -3.7980e-01,  4.1236e-01],\n",
       "          [ 2.1884e-01,  3.1009e-01, -1.4308e+00,  ...,  1.0913e+00,\n",
       "           -4.4107e-01,  1.8888e+00],\n",
       "          ...,\n",
       "          [-4.2832e-02, -1.2298e-01, -1.5415e-02,  ..., -3.5052e-02,\n",
       "            1.0139e-01, -6.8852e-02],\n",
       "          [-1.8912e-01, -6.6325e-02,  1.7864e-01,  ..., -6.7768e-02,\n",
       "            2.2371e-02,  1.5719e-01],\n",
       "          [-7.0282e-02,  1.1298e+00,  1.0945e-01,  ..., -5.6678e-03,\n",
       "            1.3885e-01, -2.4891e+00]]],\n",
       "\n",
       "\n",
       "        [[[ 2.7643e-01, -1.2601e+00,  1.3101e+00,  ...,  5.9169e-01,\n",
       "            9.6373e-01,  1.0263e+00],\n",
       "          [ 2.4917e-01,  1.0268e+00, -8.1631e-01,  ..., -2.9923e-01,\n",
       "            2.5035e+00,  3.6573e-01],\n",
       "          [-1.9482e+00,  1.9707e+00, -8.8827e-01,  ..., -5.6151e-01,\n",
       "           -2.9844e-01,  6.3400e-01],\n",
       "          ...,\n",
       "          [ 1.5756e-01,  3.5326e-02, -1.0488e-01,  ...,  1.3402e-01,\n",
       "            1.0831e-01, -5.5595e-02],\n",
       "          [-7.5777e-02,  1.6836e-01,  5.6592e-02,  ...,  9.8200e-02,\n",
       "            1.6126e-01,  1.8319e-02],\n",
       "          [-1.3667e-01, -2.7878e-02, -1.5403e-01,  ...,  9.9219e-02,\n",
       "            8.9396e-02,  1.7121e-01]],\n",
       "\n",
       "         [[-1.9857e+00,  4.1954e-01, -3.9530e-01,  ...,  1.0250e+00,\n",
       "           -5.7038e-01,  4.0248e-01],\n",
       "          [-7.1434e-01,  4.8076e-01,  7.0069e-01,  ..., -8.3016e-01,\n",
       "            1.3725e+00,  1.1834e+00],\n",
       "          [ 2.3749e+00, -4.4439e-01, -2.2205e+00,  ..., -6.2091e-01,\n",
       "           -1.1902e+00, -7.8140e-01],\n",
       "          ...,\n",
       "          [ 1.5216e-01,  2.4816e-01,  2.6225e-01,  ..., -1.2525e+00,\n",
       "           -1.2351e-01,  6.0087e-01],\n",
       "          [ 3.9150e-01,  8.2947e-01, -5.7247e-02,  ...,  2.5092e-01,\n",
       "           -1.9164e-01,  5.5917e-01],\n",
       "          [ 2.7776e-01,  8.3999e-01, -1.6845e-01,  ..., -8.4486e-02,\n",
       "           -5.1733e-02,  4.7628e-01]],\n",
       "\n",
       "         [[ 8.3268e-01, -2.4293e+00,  5.1433e-01,  ..., -3.0047e-01,\n",
       "           -1.5839e+00, -2.7102e-01],\n",
       "          [-2.5593e-01,  1.5771e+00,  3.9958e-01,  ...,  1.6137e+00,\n",
       "           -2.9261e+00,  1.7467e+00],\n",
       "          [ 1.4400e+00, -9.4923e-01, -2.8756e-01,  ..., -1.3330e+00,\n",
       "            8.3905e-01,  2.3148e+00],\n",
       "          ...,\n",
       "          [ 7.4932e-01, -6.3202e-01,  1.2720e+00,  ..., -2.4491e-01,\n",
       "            1.4459e-01, -2.9603e-01],\n",
       "          [ 3.7720e-01, -1.5228e-01, -2.5699e-01,  ..., -7.0614e-01,\n",
       "            7.6700e-01, -2.3480e-01],\n",
       "          [ 4.4464e-01, -9.7128e-03, -4.0243e-01,  ...,  3.0377e-01,\n",
       "            3.0523e-01,  2.8890e+00]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[-1.6659e+00, -3.0266e+00,  1.0469e+00,  ...,  4.8508e-01,\n",
       "           -5.1601e-01, -1.9480e+00],\n",
       "          [ 1.0329e+00, -2.1684e+00, -7.4232e-01,  ...,  8.8184e-01,\n",
       "            2.0376e+00, -2.1759e+00],\n",
       "          [ 1.6368e+00,  1.1231e+00,  1.2267e+00,  ...,  1.1770e+00,\n",
       "           -1.6578e+00,  6.5210e-01],\n",
       "          ...,\n",
       "          [-1.2622e-02, -2.8276e-01,  3.8534e-01,  ...,  3.1347e-01,\n",
       "           -3.7928e-02,  1.8313e-01],\n",
       "          [-2.0957e-01, -3.8468e-02,  3.0149e-01,  ..., -5.3984e-01,\n",
       "            9.4324e-01,  4.2484e-01],\n",
       "          [-4.0798e-01, -1.0477e-02,  1.3183e-01,  ..., -2.5923e-01,\n",
       "            6.6150e-03,  1.1498e+00]],\n",
       "\n",
       "         [[-1.3281e+00, -3.2838e-01,  1.3311e+00,  ...,  7.7916e-01,\n",
       "           -1.6820e+00,  2.4399e-01],\n",
       "          [ 1.8052e-01, -1.1653e+00,  1.0503e+00,  ...,  4.6919e-01,\n",
       "           -7.8501e-01,  1.1883e+00],\n",
       "          [-9.5257e-01,  7.1073e-01, -2.7511e-01,  ...,  4.6914e-01,\n",
       "            1.1277e+00, -1.3017e-01],\n",
       "          ...,\n",
       "          [-1.5668e+00,  2.8871e-01,  1.6476e+00,  ...,  9.0728e-02,\n",
       "            3.1245e-03,  3.5576e-02],\n",
       "          [-2.5777e-02,  7.6870e-02,  6.6882e-02,  ..., -1.7304e-02,\n",
       "           -1.8849e-02,  8.8717e-02],\n",
       "          [-3.5659e-02,  8.1145e-02, -7.3684e-02,  ...,  1.3803e-01,\n",
       "            6.4631e-02, -1.5218e-01]],\n",
       "\n",
       "         [[ 2.0386e-01, -1.0084e+00,  1.4243e+00,  ..., -2.1815e-02,\n",
       "           -9.6275e-02,  2.3760e+00],\n",
       "          [ 8.7544e-01,  1.9831e+00, -1.3378e+00,  ..., -1.9835e+00,\n",
       "            1.6316e+00, -1.3770e+00],\n",
       "          [-8.2838e-01,  1.2668e-01,  8.2722e-01,  ...,  1.1811e+00,\n",
       "            1.1718e+00, -1.3569e+00],\n",
       "          ...,\n",
       "          [-6.1849e-01,  1.5472e+00, -3.7802e-01,  ...,  1.1090e+00,\n",
       "           -3.1072e-01,  1.5179e-01],\n",
       "          [-1.6926e+00, -1.3306e-01,  3.2998e-01,  ..., -4.6358e-02,\n",
       "           -1.6710e-02, -1.3181e-01],\n",
       "          [ 7.0349e-01, -1.5688e-01, -1.1754e+00,  ..., -5.9066e-01,\n",
       "           -1.0056e+00, -2.1091e-01]]],\n",
       "\n",
       "\n",
       "        [[[-1.8354e+00, -1.2279e-01, -4.1437e-04,  ..., -8.1767e-01,\n",
       "           -1.1745e+00, -2.5819e-01],\n",
       "          [-1.1953e+00,  1.4361e+00,  1.6456e+00,  ...,  1.9987e+00,\n",
       "            1.2891e+00,  1.3447e+00],\n",
       "          [ 1.0241e+00,  8.5634e-01, -9.5563e-02,  ...,  1.4905e+00,\n",
       "           -1.5409e+00, -1.6125e+00],\n",
       "          ...,\n",
       "          [ 6.3249e-01, -8.8409e-01,  1.4248e-01,  ..., -6.7535e-01,\n",
       "           -7.3463e-01, -1.8782e-01],\n",
       "          [-5.6918e-01, -4.8016e-01,  9.8403e-02,  ...,  7.9945e-01,\n",
       "            1.3662e+00,  1.1017e-01],\n",
       "          [-3.0695e-01,  1.6206e+00, -4.2875e-01,  ...,  1.7938e+00,\n",
       "            4.2506e-01, -3.2655e-01]],\n",
       "\n",
       "         [[-4.1033e-01, -3.4273e-01, -2.2770e+00,  ..., -2.8799e-01,\n",
       "            1.1082e-02,  1.4974e+00],\n",
       "          [-6.4097e-01, -1.5743e+00, -3.3975e-01,  ...,  7.7429e-01,\n",
       "            8.8048e-01,  4.5457e-01],\n",
       "          [ 4.3139e-01, -5.8573e-01,  2.6796e+00,  ..., -8.5227e-01,\n",
       "            5.4851e-01, -2.2597e+00],\n",
       "          ...,\n",
       "          [-2.0932e-01, -2.4413e-01, -1.1184e+00,  ...,  1.0849e-01,\n",
       "            8.6984e-02, -2.0643e-01],\n",
       "          [ 1.6118e-01,  3.8696e-01,  5.9607e-02,  ...,  2.7433e-01,\n",
       "           -1.7375e+00,  2.9191e-02],\n",
       "          [-1.4447e-01, -8.3614e-02, -1.2607e-01,  ..., -1.9084e-01,\n",
       "            2.7910e-02, -2.7949e-01]],\n",
       "\n",
       "         [[-7.1368e-01,  3.0669e-01,  8.9108e-01,  ...,  1.4344e+00,\n",
       "           -1.8370e+00,  8.6998e-01],\n",
       "          [ 2.0117e+00,  1.3289e+00,  2.0725e-01,  ...,  2.0132e+00,\n",
       "           -2.4253e-01, -1.5007e-01],\n",
       "          [ 2.3339e-01,  2.0403e+00,  8.7262e-01,  ...,  1.2172e+00,\n",
       "            2.0648e-01, -1.2970e+00],\n",
       "          ...,\n",
       "          [ 1.2409e-03,  5.9806e-01, -5.0991e-01,  ...,  1.4807e-01,\n",
       "            3.3673e-01,  1.1164e+00],\n",
       "          [ 4.1743e-01,  3.6761e-01,  3.1694e-02,  ...,  7.9794e-02,\n",
       "           -5.4736e-01, -1.0285e-01],\n",
       "          [-4.9294e-03, -2.6479e-01, -2.7373e-02,  ..., -6.9387e-02,\n",
       "            6.3059e-01, -7.0744e-01]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[ 8.6369e-01,  1.0137e+00, -1.5804e-01,  ..., -1.0046e+00,\n",
       "           -1.2581e+00, -6.1368e-01],\n",
       "          [ 1.1004e+00,  2.2862e-01, -1.0633e+00,  ...,  1.2054e+00,\n",
       "           -1.1780e+00, -7.3929e-01],\n",
       "          [ 1.0242e+00, -1.0372e+00, -1.0734e+00,  ...,  6.8682e-01,\n",
       "           -1.4109e+00,  1.5992e+00],\n",
       "          ...,\n",
       "          [-1.7243e+00, -1.5582e-02,  6.6832e-01,  ..., -4.3573e-01,\n",
       "            5.7299e-01,  1.5347e-01],\n",
       "          [ 3.9590e-01,  2.3996e-01, -3.5669e-01,  ..., -7.9413e-01,\n",
       "           -1.9734e+00,  1.9671e-01],\n",
       "          [-2.0299e-01, -8.4796e-01, -3.0862e-01,  ...,  1.4477e+00,\n",
       "            9.9200e-01, -2.9525e-01]],\n",
       "\n",
       "         [[-3.2496e-01, -6.7115e-01,  1.5936e+00,  ..., -6.9802e-01,\n",
       "            4.7222e-01,  1.0640e+00],\n",
       "          [-6.6439e-01,  1.8172e+00, -1.5819e+00,  ..., -1.7456e+00,\n",
       "           -7.9090e-01, -1.1743e+00],\n",
       "          [ 1.3069e+00,  7.2181e-01,  6.2713e-01,  ...,  6.6425e-01,\n",
       "            1.0100e+00,  1.7700e+00],\n",
       "          ...,\n",
       "          [ 1.7000e-01, -1.5890e-01, -1.8072e-01,  ...,  1.5233e-01,\n",
       "           -5.4936e-02, -1.1326e-01],\n",
       "          [ 4.7472e-02, -1.1241e-01, -7.4691e-02,  ..., -8.4873e-02,\n",
       "           -2.1065e-02, -1.8371e-01],\n",
       "          [ 1.5510e-01, -4.4714e-02, -5.3900e-03,  ..., -2.6037e-02,\n",
       "            1.7998e-01, -2.2915e-01]],\n",
       "\n",
       "         [[ 1.9749e-01, -8.7275e-01, -1.0085e+00,  ..., -2.4091e-01,\n",
       "           -9.4435e-01, -3.5388e-02],\n",
       "          [ 1.7931e-01,  7.2374e-01, -1.9246e+00,  ..., -7.8966e-01,\n",
       "           -1.3231e+00,  7.0275e-01],\n",
       "          [-1.5495e+00,  1.1326e+00, -2.1484e-01,  ..., -9.7288e-01,\n",
       "            1.9515e+00,  2.1932e+00],\n",
       "          ...,\n",
       "          [ 5.0470e-01,  7.2616e-02, -1.3743e-01,  ..., -1.6575e-01,\n",
       "            4.3741e-01,  2.4554e-01],\n",
       "          [-5.5776e-01, -2.0481e-01,  2.0620e-01,  ...,  5.8187e-01,\n",
       "            4.4660e-01, -4.3467e-01],\n",
       "          [ 9.6277e-01, -7.3390e-03, -9.2268e-01,  ...,  4.3293e-01,\n",
       "            1.7207e+00, -2.5838e-01]]]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_in = torch.randn(100, 10, 28, 54)\n",
    "topk = 100000\n",
    "\n",
    "shape = x_in.shape\n",
    "x = x_in.reshape(shape[0], shape[1], -1) # [batch, class, eig]\n",
    "topk = min(topk, x.shape[-1])\n",
    "values, indices = torch.topk(x.abs(), topk, dim=-1, sorted=False)\n",
    "y = torch.zeros_like(x)\n",
    "y = y.scatter(-1, indices, x).reshape(shape)\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(x.cpu().flatten(), y.cpu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([100000])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y[y.abs() >  0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='mps', index=0)"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eigmodel = EigModel(model).to('mps')\n",
    "eigmodel.config.topk =  1000000\n",
    "eigmodel.device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation | Accuracy: 20.25 %, Loss: 2.8536\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(20.25, 2.8535824632644653)"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eigmodel.validation()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "eigmodel.set_dataset()\n",
    "inputs, labels = eigmodel.transform_inputs(*next(iter(eigmodel.train_loader)))\n",
    "embed = eigmodel.Embed(inputs)\n",
    "y = eigmodel.layers[0].forward(embed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "y[y.abs() > 0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "x = einsum(eigmodel.layers[0].eigvecs, embed, '... eig d_model, batch d_model -> batch ... eig')\n",
    "x = x**2\n",
    "x = einsum(eigmodel.eff_eigvals.to(\"mps\"), x, '... eig, batch ... eig -> batch ...')\n",
    "\n",
    "plt.hist(x[2].flatten().cpu(), bins=100)\n",
    "plt.yscale('log')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "eff_eigvals = eigmodel.eff_eigvals\n",
    "plt.hist(eff_eigvals.flatten(), bins=100, alpha=0.3)\n",
    "plt.hist(eigmodel.layers[0].eigvals.flatten().cpu(), bins = 100, alpha=0.3)\n",
    "plt.yscale('log')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([17270])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eff_eigvals[eff_eigvals.abs() > 0.001].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(299, 296)\n",
      "tensor(0.0261)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x2c843ef90>"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "idx = 3\n",
    "\n",
    "root_idx = (9,)\n",
    "eigvals = eff_eigvals[root_idx]\n",
    "topk = eigvals.flatten().topk(100)\n",
    "topk_idxs= torch.unravel_index(topk.indices, eigvals.shape)\n",
    "eigvec_idxs = tuple(topk_idxs[i][idx].item() for i in range(len(eigvals.shape)))\n",
    "print(eigvec_idxs)\n",
    "print(eigvals[eigvec_idxs])\n",
    "eigvec = eigmodel.layers[0].eigvecs[root_idx + eigvec_idxs]\n",
    "eigvec_emb = (eigvec @ eigmodel.Embed.weight).detach().cpu()\n",
    "\n",
    "plt.imshow(eigvec_emb.reshape(28,28), cmap = 'RdBu', vmin=-0.25, vmax=0.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5, 5)"
      ]
     },
     "execution_count": 235,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(5,) + (5,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
